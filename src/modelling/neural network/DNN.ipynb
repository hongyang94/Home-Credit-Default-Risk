{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DNN.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "metadata": {
        "id": "t8D7QqS6TZ7i",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 124
        },
        "outputId": "066aac77-e5b6-43e3-fc2e-ef54189fc59a"
      },
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "520Xtw4Gfq_6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "01b5b576-5369-49bc-fdff-40981f96bbcb"
      },
      "cell_type": "code",
      "source": [
        "import os\n",
        "import gc\n",
        "import pandas as pd\n",
        "pd.set_option('display.max_colwidth', -1)\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from sklearn.preprocessing import LabelEncoder, MinMaxScaler, StandardScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import roc_auc_score, roc_curve, precision_recall_curve, confusion_matrix\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "%matplotlib inline\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "from timeit import default_timer\n",
        "start = default_timer()\n",
        "\n",
        "def start_timer():\n",
        "    st = default_timer()\n",
        "    return st\n",
        "def stop_timer(st):\n",
        "    runtime = default_timer() - st\n",
        "    print (\"Elapsed time(sec): \", round(runtime,2))\n",
        "\n",
        "###### PLOTLY #############\n",
        "from plotly.offline import init_notebook_mode, iplot, plot\n",
        "import plotly.graph_objs as go\n",
        "import plotly.plotly as py\n",
        "from plotly import tools\n",
        "init_notebook_mode(connected=True)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<script>requirejs.config({paths: { 'plotly': ['https://cdn.plot.ly/plotly-latest.min']},});if(!window.Plotly) {{require(['plotly'],function(plotly) {window.Plotly=plotly;});}}</script>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "xEzGxv1Rm3oq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "outputId": "10fa575a-3f2f-47ad-f10b-a8a6732d1fd5"
      },
      "cell_type": "code",
      "source": [
        "st = start_timer()\n",
        "path = \"/content/gdrive/My Drive/Colab Notebooks/data/\"\n",
        "print('Loading data sets...')\n",
        "\n",
        "sample_size = None\n",
        "app_train_df = pd.read_csv(path + 'application_train.csv')\n",
        "app_test_df = pd.read_csv(path + 'application_test.csv')\n",
        "bureau_df = pd.read_csv(path + 'bureau.csv')\n",
        "bureau_balance_df = pd.read_csv(path + 'bureau_balance.csv')\n",
        "credit_card_df = pd.read_csv(path + 'credit_card_balance.csv')\n",
        "pos_cash_df = pd.read_csv(path + 'POS_CASH_balance.csv')\n",
        "prev_app_df = pd.read_csv(path + 'previous_application.csv')\n",
        "install_df = pd.read_csv(path + 'installments_payments.csv')\n",
        "\n",
        "print('Data loaded.\\nMain application training data set shape = {}'.format(app_train_df.shape))\n",
        "print('Main application test data set shape = {}'.format(app_test_df.shape))\n",
        "print('Positive target proportion = {:.2f}'.format(app_train_df['TARGET'].mean()))\n",
        "stop_timer(st)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loading data sets...\n",
            "Data loaded.\n",
            "Main application training data set shape = (307511, 122)\n",
            "Main application test data set shape = (48744, 121)\n",
            "Positive target proportion = 0.08\n",
            "Elapsed time(sec):  84.01\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "gt5Xce45LBMQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 252
        },
        "outputId": "fee582b3-c0b0-4980-89bf-027c403843a4"
      },
      "cell_type": "code",
      "source": [
        "app_train_df.head()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>SK_ID_CURR</th>\n",
              "      <th>TARGET</th>\n",
              "      <th>NAME_CONTRACT_TYPE</th>\n",
              "      <th>CODE_GENDER</th>\n",
              "      <th>FLAG_OWN_CAR</th>\n",
              "      <th>FLAG_OWN_REALTY</th>\n",
              "      <th>CNT_CHILDREN</th>\n",
              "      <th>AMT_INCOME_TOTAL</th>\n",
              "      <th>AMT_CREDIT</th>\n",
              "      <th>AMT_ANNUITY</th>\n",
              "      <th>...</th>\n",
              "      <th>FLAG_DOCUMENT_18</th>\n",
              "      <th>FLAG_DOCUMENT_19</th>\n",
              "      <th>FLAG_DOCUMENT_20</th>\n",
              "      <th>FLAG_DOCUMENT_21</th>\n",
              "      <th>AMT_REQ_CREDIT_BUREAU_HOUR</th>\n",
              "      <th>AMT_REQ_CREDIT_BUREAU_DAY</th>\n",
              "      <th>AMT_REQ_CREDIT_BUREAU_WEEK</th>\n",
              "      <th>AMT_REQ_CREDIT_BUREAU_MON</th>\n",
              "      <th>AMT_REQ_CREDIT_BUREAU_QRT</th>\n",
              "      <th>AMT_REQ_CREDIT_BUREAU_YEAR</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>100002</td>\n",
              "      <td>1</td>\n",
              "      <td>Cash loans</td>\n",
              "      <td>M</td>\n",
              "      <td>N</td>\n",
              "      <td>Y</td>\n",
              "      <td>0</td>\n",
              "      <td>202500.0</td>\n",
              "      <td>406597.5</td>\n",
              "      <td>24700.5</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>100003</td>\n",
              "      <td>0</td>\n",
              "      <td>Cash loans</td>\n",
              "      <td>F</td>\n",
              "      <td>N</td>\n",
              "      <td>N</td>\n",
              "      <td>0</td>\n",
              "      <td>270000.0</td>\n",
              "      <td>1293502.5</td>\n",
              "      <td>35698.5</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>100004</td>\n",
              "      <td>0</td>\n",
              "      <td>Revolving loans</td>\n",
              "      <td>M</td>\n",
              "      <td>Y</td>\n",
              "      <td>Y</td>\n",
              "      <td>0</td>\n",
              "      <td>67500.0</td>\n",
              "      <td>135000.0</td>\n",
              "      <td>6750.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>100006</td>\n",
              "      <td>0</td>\n",
              "      <td>Cash loans</td>\n",
              "      <td>F</td>\n",
              "      <td>N</td>\n",
              "      <td>Y</td>\n",
              "      <td>0</td>\n",
              "      <td>135000.0</td>\n",
              "      <td>312682.5</td>\n",
              "      <td>29686.5</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>100007</td>\n",
              "      <td>0</td>\n",
              "      <td>Cash loans</td>\n",
              "      <td>M</td>\n",
              "      <td>N</td>\n",
              "      <td>Y</td>\n",
              "      <td>0</td>\n",
              "      <td>121500.0</td>\n",
              "      <td>513000.0</td>\n",
              "      <td>21865.5</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 122 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "   SK_ID_CURR  TARGET NAME_CONTRACT_TYPE CODE_GENDER FLAG_OWN_CAR  \\\n",
              "0  100002      1       Cash loans         M           N             \n",
              "1  100003      0       Cash loans         F           N             \n",
              "2  100004      0       Revolving loans    M           Y             \n",
              "3  100006      0       Cash loans         F           N             \n",
              "4  100007      0       Cash loans         M           N             \n",
              "\n",
              "  FLAG_OWN_REALTY  CNT_CHILDREN  AMT_INCOME_TOTAL  AMT_CREDIT  AMT_ANNUITY  \\\n",
              "0  Y               0             202500.0          406597.5    24700.5       \n",
              "1  N               0             270000.0          1293502.5   35698.5       \n",
              "2  Y               0             67500.0           135000.0    6750.0        \n",
              "3  Y               0             135000.0          312682.5    29686.5       \n",
              "4  Y               0             121500.0          513000.0    21865.5       \n",
              "\n",
              "              ...              FLAG_DOCUMENT_18 FLAG_DOCUMENT_19  \\\n",
              "0             ...              0                 0                 \n",
              "1             ...              0                 0                 \n",
              "2             ...              0                 0                 \n",
              "3             ...              0                 0                 \n",
              "4             ...              0                 0                 \n",
              "\n",
              "  FLAG_DOCUMENT_20 FLAG_DOCUMENT_21 AMT_REQ_CREDIT_BUREAU_HOUR  \\\n",
              "0  0                0                0.0                         \n",
              "1  0                0                0.0                         \n",
              "2  0                0                0.0                         \n",
              "3  0                0               NaN                          \n",
              "4  0                0                0.0                         \n",
              "\n",
              "  AMT_REQ_CREDIT_BUREAU_DAY  AMT_REQ_CREDIT_BUREAU_WEEK  \\\n",
              "0  0.0                       0.0                          \n",
              "1  0.0                       0.0                          \n",
              "2  0.0                       0.0                          \n",
              "3 NaN                       NaN                           \n",
              "4  0.0                       0.0                          \n",
              "\n",
              "   AMT_REQ_CREDIT_BUREAU_MON  AMT_REQ_CREDIT_BUREAU_QRT  \\\n",
              "0  0.0                        0.0                         \n",
              "1  0.0                        0.0                         \n",
              "2  0.0                        0.0                         \n",
              "3 NaN                        NaN                          \n",
              "4  0.0                        0.0                         \n",
              "\n",
              "   AMT_REQ_CREDIT_BUREAU_YEAR  \n",
              "0  1.0                         \n",
              "1  0.0                         \n",
              "2  0.0                         \n",
              "3 NaN                          \n",
              "4  0.0                         \n",
              "\n",
              "[5 rows x 122 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "metadata": {
        "id": "OmPvZiF_K3pL",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def feature_engineering(app_data, bureau_df, bureau_balance_df, credit_card_df,\n",
        "                        pos_cash_df, prev_app_df, install_df):\n",
        "    \"\"\" \n",
        "    Process the input dataframes into a single one containing all the features. Requires\n",
        "    a lot of aggregating of the supplementary datasets such that they have an entry per\n",
        "    customer.\n",
        "    \n",
        "    Also, add any new features created from the existing ones\n",
        "    \"\"\"\n",
        "    # Clean Data\n",
        "    # Days_Employed\n",
        "    app_data['DAYS_EMPLOYED'] = app_data['DAYS_EMPLOYED'].replace({365243: np.nan}, inplace = True)\n",
        "    \n",
        "    # # Add new features\n",
        "    \n",
        "    # Amount loaned relative to salary\n",
        "    app_data['LOAN_INCOME_RATIO'] = app_data['AMT_CREDIT'] / app_data['AMT_INCOME_TOTAL']\n",
        "    app_data['ANNUITY_INCOME_RATIO'] = app_data['AMT_ANNUITY'] / app_data['AMT_INCOME_TOTAL']\n",
        "    app_data['ANNUITY LENGTH'] = app_data['AMT_CREDIT'] / app_data['AMT_ANNUITY']\n",
        "    #app_data['DAY_EMPLOYED_PERCENT'] = app_data['DAYS_EMPLOYED'] / app_data['DAYS_BIRTH']\n",
        "    app_data['EXT_SOURCE_2 EXT_SOURCE_3'] = app_data['EXT_SOURCE_2'] * app_data['EXT_SOURCE_3']\n",
        "    app_data['EXT_SOURCE_1 EXT_SOURCE_2 EXT_SOURCE_3'] = app_data['EXT_SOURCE_1'] * app_data['EXT_SOURCE_2'] * app_data['EXT_SOURCE_3']\n",
        "    app_data['EXT_SOURCE_2 EXT_SOURCE_3 DAYS_BIRTH'] = app_data['EXT_SOURCE_2'] * app_data['EXT_SOURCE_3'] * app_data['DAYS_BIRTH']\n",
        "    app_data['EXT_SOURCE_2^2 EXT_SOURCE_3'] = (app_data['EXT_SOURCE_2'] ** 2) * app_data['EXT_SOURCE_3']\n",
        "    app_data['EXT_SOURCE_2 EXT_SOURCE_3^2'] = app_data['EXT_SOURCE_2'] * (app_data['EXT_SOURCE_3'] ** 2)\n",
        "    \n",
        "    # # Aggregate and merge supplementary datasets\n",
        "    print('Combined train & test input shape before any merging  = {}'.format(app_data.shape))\n",
        "\n",
        "    # Previous applications\n",
        "    agg_funs = {'SK_ID_CURR': 'count', 'AMT_CREDIT': 'sum'}\n",
        "    prev_apps = prev_app_df.groupby('SK_ID_CURR').agg(agg_funs)\n",
        "    prev_apps.columns = ['PREV APP COUNT', 'TOTAL PREV LOAN AMT']\n",
        "    merged_df = app_data.merge(prev_apps, left_on='SK_ID_CURR', right_index=True, how='left')\n",
        "\n",
        "    # Average the rest of the previous app data\n",
        "    prev_apps_avg = prev_app_df.groupby('SK_ID_CURR').mean()\n",
        "    merged_df = merged_df.merge(prev_apps_avg, left_on='SK_ID_CURR', right_index=True,\n",
        "                                how='left', suffixes=['', '_PAVG'])\n",
        "    print('Shape after merging with previous apps num data = {}'.format(merged_df.shape))\n",
        "    \n",
        "    # Previous app categorical features\n",
        "    prev_app_df, cat_feats, _ = process_dataframe(prev_app_df)\n",
        "    prev_apps_cat_avg = prev_app_df[cat_feats + ['SK_ID_CURR']].groupby('SK_ID_CURR')\\\n",
        "                             .agg({k: lambda x: str(x.mode().iloc[0]) for k in cat_feats})\n",
        "    merged_df = merged_df.merge(prev_apps_cat_avg, left_on='SK_ID_CURR', right_index=True,\n",
        "                            how='left', suffixes=['', '_BAVG'])\n",
        "    print('Shape after merging with previous apps cat data = {}'.format(merged_df.shape))\n",
        "\n",
        "    # Credit card data - numerical features\n",
        "    wm = lambda x: np.average(x, weights=-1/credit_card_df.loc[x.index, 'MONTHS_BALANCE'])\n",
        "    credit_card_avgs = credit_card_df.groupby('SK_ID_CURR').agg(wm)   \n",
        "    merged_df = merged_df.merge(credit_card_avgs, left_on='SK_ID_CURR', right_index=True,\n",
        "                                how='left', suffixes=['', '_CCAVG'])\n",
        "    \n",
        "    # Credit card data - categorical features\n",
        "    most_recent_index = credit_card_df.groupby('SK_ID_CURR')['MONTHS_BALANCE'].idxmax()\n",
        "    cat_feats = credit_card_df.columns[credit_card_df.dtypes == 'object'].tolist()  + ['SK_ID_CURR']\n",
        "    merged_df = merged_df.merge(credit_card_df.loc[most_recent_index, cat_feats], left_on='SK_ID_CURR', right_on='SK_ID_CURR',\n",
        "                       how='left', suffixes=['', '_CCAVG'])\n",
        "    print('Shape after merging with credit card data = {}'.format(merged_df.shape))\n",
        "\n",
        "    # Credit bureau data - numerical features\n",
        "    credit_bureau_avgs = bureau_df.groupby('SK_ID_CURR').mean()\n",
        "    merged_df = merged_df.merge(credit_bureau_avgs, left_on='SK_ID_CURR', right_index=True,\n",
        "                                how='left', suffixes=['', '_BAVG'])\n",
        "    print('Shape after merging with credit bureau data = {}'.format(merged_df.shape))\n",
        "    \n",
        "    # Bureau balance data\n",
        "    most_recent_index = bureau_balance_df.groupby('SK_ID_BUREAU')['MONTHS_BALANCE'].idxmax()\n",
        "    bureau_balance_df = bureau_balance_df.loc[most_recent_index, :]\n",
        "    merged_df = merged_df.merge(bureau_balance_df, left_on='SK_ID_BUREAU', right_on='SK_ID_BUREAU',\n",
        "                            how='left', suffixes=['', '_B_B'])\n",
        "    print('Shape after merging with bureau balance data = {}'.format(merged_df.shape))\n",
        "\n",
        "    # Pos cash data - weight values by recency when averaging\n",
        "    wm = lambda x: np.average(x, weights=-1/pos_cash_df.loc[x.index, 'MONTHS_BALANCE'])\n",
        "    f = {'CNT_INSTALMENT': wm, 'CNT_INSTALMENT_FUTURE': wm, 'SK_DPD': wm, 'SK_DPD_DEF':wm}\n",
        "    cash_avg = pos_cash_df.groupby('SK_ID_CURR')['CNT_INSTALMENT','CNT_INSTALMENT_FUTURE',\n",
        "                                                 'SK_DPD', 'SK_DPD_DEF'].agg(f)\n",
        "    merged_df = merged_df.merge(cash_avg, left_on='SK_ID_CURR', right_index=True,\n",
        "                                how='left', suffixes=['', '_CAVG'])\n",
        "    \n",
        "    # Pos cash data data - categorical features\n",
        "    most_recent_index = pos_cash_df.groupby('SK_ID_CURR')['MONTHS_BALANCE'].idxmax()\n",
        "    cat_feats = pos_cash_df.columns[pos_cash_df.dtypes == 'object'].tolist()  + ['SK_ID_CURR']\n",
        "    merged_df = merged_df.merge(pos_cash_df.loc[most_recent_index, cat_feats], left_on='SK_ID_CURR', right_on='SK_ID_CURR',\n",
        "                       how='left', suffixes=['', '_CAVG'])\n",
        "    print('Shape after merging with pos cash data = {}'.format(merged_df.shape))\n",
        "\n",
        "    # Installments data\n",
        "    ins_avg = install_df.groupby('SK_ID_CURR').mean()\n",
        "    merged_df = merged_df.merge(ins_avg, left_on='SK_ID_CURR', right_index=True,\n",
        "                                how='left', suffixes=['', '_IAVG'])\n",
        "    print('Shape after merging with installments data = {}'.format(merged_df.shape))\n",
        "    \n",
        "    # Add more value counts\n",
        "    merged_df = merged_df.merge(pd.DataFrame(bureau_df['SK_ID_CURR'].value_counts()), left_on='SK_ID_CURR', \n",
        "                                right_index=True, how='left', suffixes=['', '_CNT_BUREAU'])\n",
        "    merged_df = merged_df.merge(pd.DataFrame(credit_card_df['SK_ID_CURR'].value_counts()), left_on='SK_ID_CURR', \n",
        "                                right_index=True, how='left', suffixes=['', '_CNT_CRED_CARD'])\n",
        "    merged_df = merged_df.merge(pd.DataFrame(pos_cash_df['SK_ID_CURR'].value_counts()), left_on='SK_ID_CURR', \n",
        "                                right_index=True, how='left', suffixes=['', '_CNT_POS_CASH'])\n",
        "    merged_df = merged_df.merge(pd.DataFrame(install_df['SK_ID_CURR'].value_counts()), left_on='SK_ID_CURR', \n",
        "                                right_index=True, how='left', suffixes=['', '_CNT_INSTALL'])\n",
        "    print('Shape after merging with counts data = {}'.format(merged_df.shape))\n",
        "\n",
        "    return merged_df"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "4zJP4_W7LDrH",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def process_dataframe(input_df, encoder_dict=None):\n",
        "    \"\"\" Process a dataframe into a form useable by LightGBM \"\"\"\n",
        "\n",
        "    # Label encode categoricals\n",
        "    categorical_feats = input_df.columns[input_df.dtypes == 'object']\n",
        "    categorical_feats = categorical_feats\n",
        "    encoder_dict = {}\n",
        "    for feat in categorical_feats:\n",
        "        encoder = LabelEncoder()\n",
        "        input_df[feat] = encoder.fit_transform(input_df[feat].fillna('NULL'))\n",
        "        encoder_dict[feat] = encoder\n",
        "\n",
        "    return input_df, categorical_feats.tolist(), encoder_dict"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "pa7wJY8pLGyX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 191
        },
        "outputId": "87d4047e-574e-4b53-d57a-f4784fd0f9e8"
      },
      "cell_type": "code",
      "source": [
        "st = start_timer()\n",
        "# Merge the datasets into a single one for training\n",
        "len_train = len(app_train_df)\n",
        "app_both = pd.concat([app_train_df, app_test_df])\n",
        "merged_df = feature_engineering(app_both, bureau_df, bureau_balance_df, credit_card_df,\n",
        "                                pos_cash_df, prev_app_df, install_df)\n",
        "\n",
        "# Separate metadata\n",
        "meta_cols = ['SK_ID_CURR', 'SK_ID_BUREAU', 'SK_ID_PREV']\n",
        "meta_df = merged_df[meta_cols]\n",
        "merged_df.drop(meta_cols, axis=1, inplace=True)\n",
        "\n",
        "# Process the data set.\n",
        "merged_df, categorical_feats, encoder_dict = process_dataframe(input_df=merged_df)\n",
        "stop_timer(st)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Combined train & test input shape before any merging  = (356255, 130)\n",
            "Shape after merging with previous apps num data = (356255, 152)\n",
            "Shape after merging with previous apps cat data = (356255, 168)\n",
            "Shape after merging with credit card data = (356255, 190)\n",
            "Shape after merging with credit bureau data = (356255, 203)\n",
            "Shape after merging with bureau balance data = (356255, 205)\n",
            "Shape after merging with pos cash data = (356255, 210)\n",
            "Shape after merging with installments data = (356255, 217)\n",
            "Shape after merging with counts data = (356255, 221)\n",
            "Elapsed time(sec):  3010.92\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "tm8gd0snLLXS",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "\n",
        "*  Combined train & test input shape before any merging  = (356255, 125)\n",
        "*  Shape after merging with previous apps num data = (356255, 147)\n",
        "*  Shape after merging with previous apps cat data = (356255, 163)\n",
        "*  Shape after merging with credit card data = (356255, 185)\n",
        "*  Shape after merging with credit bureau data = (356255, 198)\n",
        "*  Shape after merging with bureau balance data = (356255, 200)\n",
        "*  Shape after merging with pos cash data = (356255, 205)\n",
        "*  Shape after merging with installments data = (356255, 212)\n",
        "*  Shape after merging with counts data = (356255, 216)\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "Qa818VAMLJTc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "5315646e-2b4b-4ec8-93e8-c2dc38691d93"
      },
      "cell_type": "code",
      "source": [
        "st = start_timer()\n",
        "# Capture other categorical features not as object data types:\n",
        "non_obj_categoricals = [\n",
        "    'FONDKAPREMONT_MODE',\n",
        "    'HOUR_APPR_PROCESS_START',\n",
        "    'HOUSETYPE_MODE',\n",
        "    'NAME_EDUCATION_TYPE',\n",
        "    'NAME_FAMILY_STATUS', \n",
        "    'NAME_HOUSING_TYPE',\n",
        "    'NAME_INCOME_TYPE', \n",
        "    'NAME_TYPE_SUITE', \n",
        "    'OCCUPATION_TYPE',\n",
        "    'ORGANIZATION_TYPE', \n",
        "    'WALLSMATERIAL_MODE',\n",
        "    'WEEKDAY_APPR_PROCESS_START', \n",
        "    'NAME_CONTRACT_TYPE_BAVG',\n",
        "    'WEEKDAY_APPR_PROCESS_START_BAVG',\n",
        "    'NAME_CASH_LOAN_PURPOSE', \n",
        "    'NAME_CONTRACT_STATUS', \n",
        "    'NAME_PAYMENT_TYPE',\n",
        "    'CODE_REJECT_REASON', \n",
        "    'NAME_TYPE_SUITE_BAVG', \n",
        "    'NAME_CLIENT_TYPE',\n",
        "    'NAME_GOODS_CATEGORY', \n",
        "    'NAME_PORTFOLIO', \n",
        "    'NAME_PRODUCT_TYPE',\n",
        "    'CHANNEL_TYPE', \n",
        "    'NAME_SELLER_INDUSTRY', \n",
        "    'NAME_YIELD_GROUP',\n",
        "    'PRODUCT_COMBINATION', \n",
        "    'NAME_CONTRACT_STATUS_CCAVG', \n",
        "    'STATUS',\n",
        "    'NAME_CONTRACT_STATUS_CAVG'\n",
        "]\n",
        "categorical_feats = categorical_feats + non_obj_categoricals\n",
        "stop_timer(st)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Elapsed time(sec):  0.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "LKBrdLc9LZ9e",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "15b8b5aa-434a-4cfb-a758-dd7351d7ddca"
      },
      "cell_type": "code",
      "source": [
        "st = start_timer()\n",
        "# Extract target before scaling\n",
        "labels = merged_df.pop('TARGET')\n",
        "labels = labels[:len_train]\n",
        "\n",
        "# Reshape (one-hot)\n",
        "target = np.zeros([len(labels), len(np.unique(labels))])\n",
        "target[:, 0] = labels == 0\n",
        "target[:, 1] = labels == 1\n",
        "stop_timer(st)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Elapsed time(sec):  0.16\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "zZWHdY-GLcx-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 261
        },
        "outputId": "c993d525-0851-4e89-b747-d0872721e69f"
      },
      "cell_type": "code",
      "source": [
        "st = start_timer()\n",
        "null_counts = merged_df.isnull().sum()\n",
        "null_counts = null_counts[null_counts > 0]\n",
        "null_ratios = null_counts / len(merged_df)\n",
        "\n",
        "# Drop columns over x% null\n",
        "null_thresh = .8\n",
        "null_cols = null_ratios[null_ratios > null_thresh].index\n",
        "merged_df.drop(null_cols, axis=1, inplace=True)\n",
        "print('Columns dropped for being over {}% null:'.format(100*null_thresh))\n",
        "for col in null_cols:\n",
        "    print(col)\n",
        "    if col in categorical_feats:\n",
        "        categorical_feats.pop(col)\n",
        "    \n",
        "# Fill the rest with the mean (TODO: do something better!)\n",
        "merged_df.fillna(merged_df.median(), inplace=True)\n",
        "# merged_df.fillna(0, inplace=True)\n",
        "stop_timer(st)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Columns dropped for being over 80.0% null:\n",
            "RATE_INTEREST_PRIMARY\n",
            "RATE_INTEREST_PRIVILEGED\n",
            "AMT_DRAWINGS_ATM_CURRENT\n",
            "AMT_DRAWINGS_OTHER_CURRENT\n",
            "AMT_DRAWINGS_POS_CURRENT\n",
            "AMT_INST_MIN_REGULARITY\n",
            "AMT_PAYMENT_CURRENT\n",
            "CNT_DRAWINGS_ATM_CURRENT\n",
            "CNT_DRAWINGS_OTHER_CURRENT\n",
            "CNT_DRAWINGS_POS_CURRENT\n",
            "CNT_INSTALMENT_MATURE_CUM\n",
            "MONTHS_BALANCE_B_B\n",
            "Elapsed time(sec):  7.46\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "9rHMw6oFLepC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 203
        },
        "outputId": "26e2c049-87e9-44a3-c214-4dbc9965a38a"
      },
      "cell_type": "code",
      "source": [
        "cat_feats_idx = np.array([merged_df.columns.get_loc(x) for x in categorical_feats])\n",
        "int_feats_idx = [merged_df.columns.get_loc(x) for x in non_obj_categoricals]\n",
        "cat_feat_lookup = pd.DataFrame({'feature': categorical_feats, 'column_index': cat_feats_idx})\n",
        "cat_feat_lookup.head()"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>column_index</th>\n",
              "      <th>feature</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>18</td>\n",
              "      <td>CODE_GENDER</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>23</td>\n",
              "      <td>DAYS_EMPLOYED</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>32</td>\n",
              "      <td>EMERGENCYSTATE_MODE</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>63</td>\n",
              "      <td>FLAG_OWN_CAR</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>64</td>\n",
              "      <td>FLAG_OWN_REALTY</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   column_index              feature\n",
              "0  18            CODE_GENDER        \n",
              "1  23            DAYS_EMPLOYED      \n",
              "2  32            EMERGENCYSTATE_MODE\n",
              "3  63            FLAG_OWN_CAR       \n",
              "4  64            FLAG_OWN_REALTY    "
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "metadata": {
        "id": "OPq3IYaXLhWG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 203
        },
        "outputId": "9188d54f-245f-473c-ae05-0fac62445280"
      },
      "cell_type": "code",
      "source": [
        "cont_feats_idx = np.array(\n",
        "    [merged_df.columns.get_loc(x) \n",
        "     for x in merged_df.columns[~merged_df.columns.isin(categorical_feats)]]\n",
        ")\n",
        "cont_feat_lookup = pd.DataFrame(\n",
        "    {'feature': merged_df.columns[~merged_df.columns.isin(categorical_feats)], \n",
        "     'column_index': cont_feats_idx}\n",
        ")\n",
        "cont_feat_lookup.head()"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>column_index</th>\n",
              "      <th>feature</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>AMT_ANNUITY</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>AMT_CREDIT</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>AMT_GOODS_PRICE</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>AMT_INCOME_TOTAL</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>AMT_REQ_CREDIT_BUREAU_DAY</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   column_index                    feature\n",
              "0  0             AMT_ANNUITY              \n",
              "1  1             AMT_CREDIT               \n",
              "2  2             AMT_GOODS_PRICE          \n",
              "3  3             AMT_INCOME_TOTAL         \n",
              "4  4             AMT_REQ_CREDIT_BUREAU_DAY"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "metadata": {
        "id": "i6-srx2NLiV5",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "scaler = StandardScaler()\n",
        "final_col_names = merged_df.columns\n",
        "merged_df = merged_df.values\n",
        "merged_df[:, cont_feats_idx] = scaler.fit_transform(merged_df[:, cont_feats_idx])\n",
        "\n",
        "scaler_2 = MinMaxScaler(feature_range=(0, 1))\n",
        "merged_df[:, int_feats_idx] = scaler_2.fit_transform(merged_df[:, int_feats_idx])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "dJOEqPgCLj0B",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Re-separate into labelled and unlabelled\n",
        "train_df = merged_df[:len_train]\n",
        "predict_df = merged_df[len_train:]\n",
        "del merged_df, app_train_df, app_test_df, bureau_df, bureau_balance_df, credit_card_df, pos_cash_df, prev_app_df\n",
        "gc.collect()\n",
        "\n",
        "# Create a validation set to check training performance\n",
        "X_train, X_valid, y_train, y_valid = train_test_split(train_df, target, test_size=0.1, random_state=2, stratify=target[:, 0])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "XRoHVQZ4LlaQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "5555624a-0db8-4835-8dde-06b448efc24c"
      },
      "cell_type": "code",
      "source": [
        "# Fixed graph parameters\n",
        "# EMBEDDING_SIZE = 3  # Use cardinality / 2 instead\n",
        "N_HIDDEN_1 = 100\n",
        "N_HIDDEN_2 = 100\n",
        "N_HIDDEN_3 = 50\n",
        "n_cont_inputs = X_train[:, cont_feats_idx].shape[1]\n",
        "n_classes = 2\n",
        "\n",
        "# Learning parameters\n",
        "LEARNING_RATE = 0.01\n",
        "N_EPOCHS = 30\n",
        "N_ITERATIONS = 400\n",
        "BATCH_SIZE = 300\n",
        "\n",
        "print('Number of continous features: ', n_cont_inputs)\n",
        "print('Number of categoricals pre-embedding: ', X_train[:, cat_feats_idx].shape[1])"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of continous features:  168\n",
            "Number of categoricals pre-embedding:  66\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "cXaKqbe4LnTb",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def embed_and_attach(X, X_cat, cardinality):  \n",
        "    embedding = tf.Variable(tf.random_uniform([cardinality, cardinality // 2], -1.0, 1.0))\n",
        "    embedded_x = tf.nn.embedding_lookup(embedding, X_cat) \n",
        "    return tf.concat([embedded_x, X], axis=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "e-3oAf1nLovr",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# # Graph\n",
        "tf.reset_default_graph()\n",
        "\n",
        "# Define placeholders for the categorical varaibles\n",
        "cat_placeholders, cat_cardinalities = [], []\n",
        "for idx in cat_feats_idx:\n",
        "    exec('X_cat_{} = tf.placeholder(tf.int32, shape=(None, ), name=\\'X_cat_{}\\')'.format(idx, idx))\n",
        "    exec('cat_placeholders.append(X_cat_{})'.format(idx))\n",
        "    cat_cardinalities.append(len(np.unique(np.concatenate([train_df[:, idx], \n",
        "                                                           predict_df[:, idx]], axis=0))))\n",
        "    \n",
        "# Other placeholders\n",
        "X_cont = tf.placeholder(tf.float32, shape=(None, n_cont_inputs), name='X_cont')\n",
        "y = tf.placeholder(tf.int32, shape=(None, n_classes), name='labels')\n",
        "train_mode = tf.placeholder(tf.bool)\n",
        "\n",
        "# Add embeddings to input\n",
        "X = tf.identity(X_cont)\n",
        "for feat, card in zip(cat_placeholders, cat_cardinalities):\n",
        "    X = embed_and_attach(X, feat, card)\n",
        "\n",
        "# Define the network layers. \n",
        "# Overfitting is a challenge so add L2 regularisation to weights in 1st layer & \n",
        "# a couple of dropout layers\n",
        "with tf.name_scope('dnn'):\n",
        "    hidden_layer_1 = tf.layers.dense(inputs=X,\n",
        "                                     units=N_HIDDEN_1,\n",
        "                                     name='first_hidden_layer',\n",
        "                                     kernel_regularizer=tf.contrib.layers.l2_regularizer(scale=0.3))\n",
        "    hidden_layer_1 = tf.layers.batch_normalization(hidden_layer_1, training=train_mode)\n",
        "    hidden_layer_1 = tf.nn.relu(hidden_layer_1)\n",
        "    \n",
        "    drop_layer_1 = tf.layers.dropout(inputs=hidden_layer_1, \n",
        "                                     rate=0.4, \n",
        "                                     name='first_dropout_layer',\n",
        "                                     training=train_mode)\n",
        "\n",
        "    hidden_layer_2 = tf.layers.dense(inputs=drop_layer_1,\n",
        "                                     units=N_HIDDEN_2,\n",
        "                                     name='second_hidden_layer',\n",
        "                                     kernel_regularizer=tf.contrib.layers.l2_regularizer(scale=0.1))\n",
        "    hidden_layer_2 = tf.layers.batch_normalization(hidden_layer_2, training=train_mode)\n",
        "    hidden_layer_2 = tf.nn.relu(hidden_layer_2)\n",
        "                                     \n",
        "    drop_layer_2 = tf.layers.dropout(inputs=hidden_layer_2, \n",
        "                                     rate=0.2, \n",
        "                                     name='second_dropout_layer',\n",
        "                                     training=train_mode)\n",
        "\n",
        "    hidden_layer_3 = tf.layers.dense(inputs=drop_layer_2,\n",
        "                                     units=N_HIDDEN_3,\n",
        "                                     name='third_hidden_layer')\n",
        "    hidden_layer_3 = tf.layers.batch_normalization(hidden_layer_3, training=train_mode)\n",
        "    hidden_layer_3 = tf.nn.relu(hidden_layer_3)\n",
        "\n",
        "    logits = tf.layers.dense(inputs=hidden_layer_3,\n",
        "                             units=n_classes,\n",
        "                             name='outputs')\n",
        "\n",
        "# Define the loss function for training as cross entropy\n",
        "with tf.name_scope('loss'):\n",
        "    xent = tf.nn.softmax_cross_entropy_with_logits_v2(labels=y, logits=logits)\n",
        "    loss = tf.reduce_mean(xent, name='loss')\n",
        "\n",
        "# Define the optimiser\n",
        "with tf.name_scope('train'):\n",
        "    optimiser = tf.train.AdamOptimizer()  # AdagradOptimizer(learning_rate=LEARNING_RATE)\n",
        "    train_step = optimiser.minimize(loss)\n",
        "\n",
        "# Output the class probabilities to I can get the AUC\n",
        "with tf.name_scope('eval'):\n",
        "    predict = tf.argmax(logits, axis=1, name='class_predictions')\n",
        "    predict_proba = tf.nn.softmax(logits, name='probability_predictions')\n",
        "\n",
        "# Initialisation node and saver\n",
        "init = tf.global_variables_initializer()\n",
        "saver = tf.train.Saver()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "AMehVyryLqe6",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def get_feed_dict(cat_feats_idx, cat_placeholders, cont_feats_idx, batch_X, batch_y=None,\n",
        "                 training=False):\n",
        "    \"\"\" Return a feed dict for the graph including all the categorical features\n",
        "    to embed \"\"\"\n",
        "    \n",
        "    # Continuous X features and the labels if training run\n",
        "    feed_dict = {X_cont: batch_X[:, cont_feats_idx]}\n",
        "    if batch_y is not None:\n",
        "        feed_dict[y] = batch_y\n",
        "        \n",
        "    # Loop through the categorical features to provide values for the placeholders\n",
        "    for idx, tensor in zip(cat_feats_idx, cat_placeholders):\n",
        "        feed_dict[tensor] = batch_X[:, idx].reshape(-1, ).astype(int)\n",
        "        \n",
        "    # Training mode or not\n",
        "    feed_dict[train_mode] = training\n",
        "        \n",
        "    return feed_dict"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "s6RzbV-aLtnV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        },
        "outputId": "e166c25b-6da9-4357-eb02-473e106ac1fb"
      },
      "cell_type": "code",
      "source": [
        "st = start_timer()\n",
        "train_auc, valid_auc = [], []\n",
        "n_rounds_not_improved = 0\n",
        "early_stopping_epochs = 2\n",
        "with tf.Session() as sess:\n",
        "\n",
        "    init.run()\n",
        "\n",
        "    # Begin epoch loop\n",
        "    print('Training for {} iterations over {} epochs with batchsize {} ...'\n",
        "          .format(N_ITERATIONS, N_EPOCHS, BATCH_SIZE))\n",
        "    for epoch in range(N_EPOCHS):\n",
        "        \n",
        "        # Iteration loop\n",
        "        for iteration in range(N_ITERATIONS):\n",
        "\n",
        "            # Get random selection of data for batch GD. Upsample positive classes to make it\n",
        "            # balanced in the training batch\n",
        "            pos_ratio = 0.5\n",
        "            pos_idx = np.random.choice(np.where(y_train[:, 1] == 1)[0], \n",
        "                                       size=int(np.round(BATCH_SIZE*pos_ratio)))\n",
        "            neg_idx = np.random.choice(np.where(y_train[:, 1] == 0)[0], \n",
        "                                       size=int(np.round(BATCH_SIZE*(1-pos_ratio))))\n",
        "            idx = np.concatenate([pos_idx, neg_idx])\n",
        "            \n",
        "            # Run training\n",
        "            extra_update_ops = tf.get_collection(tf.GraphKeys.UPDATE_OPS)\n",
        "            sess.run([train_step, extra_update_ops], \n",
        "                     feed_dict=get_feed_dict(cat_feats_idx, cat_placeholders, cont_feats_idx, \n",
        "                                             X_train[idx, :], y_train[idx, :], 1))\n",
        "\n",
        "        # Check on the AUC\n",
        "        y_pred_train, y_prob_train = sess.run(\n",
        "            [predict, predict_proba], feed_dict=get_feed_dict(\n",
        "                cat_feats_idx, cat_placeholders, cont_feats_idx, X_train, y_train, False))\n",
        "        train_auc.append(roc_auc_score(y_train[:, 1], y_prob_train[:, 1]))\n",
        "        \n",
        "        y_pred_val, y_prob_val = sess.run(\n",
        "            [predict, predict_proba], feed_dict=get_feed_dict(\n",
        "                cat_feats_idx, cat_placeholders, cont_feats_idx, X_valid, y_valid, False))\n",
        "        valid_auc.append(roc_auc_score(y_valid[:, 1], y_prob_val[:, 1]))\n",
        "        \n",
        "        # Early stopping\n",
        "        if epoch > 1:\n",
        "            best_epoch_so_far = np.argmax(valid_auc[:-1])\n",
        "            if valid_auc[epoch] <= valid_auc[best_epoch_so_far]:\n",
        "                n_rounds_not_improved += 1\n",
        "            else:\n",
        "                n_rounds_not_improved = 0       \n",
        "            if n_rounds_not_improved > early_stopping_epochs:\n",
        "                print('Early stopping due to no improvement after {} epochs.'\n",
        "                      .format(early_stopping_epochs))\n",
        "                break\n",
        "        print('Epoch = {}, Train AUC = {:.8f}, Valid AUC = {:.8f}'\n",
        "              .format(epoch, train_auc[epoch], valid_auc[epoch]))\n",
        "\n",
        "    # Once trained, make predictions\n",
        "    print('Training complete.')\n",
        "    y_prob = sess.run(predict_proba, feed_dict=get_feed_dict(\n",
        "        cat_feats_idx, cat_placeholders, cont_feats_idx, predict_df, None, False))\n",
        "\n",
        "stop_timer(st)"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training for 400 iterations over 30 epochs with batchsize 300 ...\n",
            "Epoch = 0, Train AUC = 0.75105433, Valid AUC = 0.74024143\n",
            "Epoch = 1, Train AUC = 0.76357074, Valid AUC = 0.74927317\n",
            "Epoch = 2, Train AUC = 0.76693457, Valid AUC = 0.75112312\n",
            "Epoch = 3, Train AUC = 0.76968952, Valid AUC = 0.75274677\n",
            "Epoch = 4, Train AUC = 0.77299562, Valid AUC = 0.75352643\n",
            "Epoch = 5, Train AUC = 0.77444835, Valid AUC = 0.75491834\n",
            "Epoch = 6, Train AUC = 0.77765655, Valid AUC = 0.75470104\n",
            "Epoch = 7, Train AUC = 0.78062070, Valid AUC = 0.75519531\n",
            "Epoch = 9, Train AUC = 0.78418192, Valid AUC = 0.75877864\n",
            "Epoch = 10, Train AUC = 0.78394370, Valid AUC = 0.75757511\n",
            "Epoch = 11, Train AUC = 0.78826757, Valid AUC = 0.75866877\n",
            "Early stopping due to no improvement after 2 epochs.\n",
            "Training complete.\n",
            "Elapsed time(sec):  234.76\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "mn4cD1zcLujy",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 369
        },
        "outputId": "43ad328e-f289-447f-9ec4-a5341b28fbeb"
      },
      "cell_type": "code",
      "source": [
        "fig, (ax, ax1) = plt.subplots(1, 2, figsize=[14, 5])\n",
        "ax.plot(np.arange(len(train_auc)), train_auc, label='Train')\n",
        "ax.plot(np.arange(len(valid_auc)), valid_auc, label='Valid')\n",
        "ax.set_xlabel('Epoch')\n",
        "ax.set_ylabel('AUC')\n",
        "ax.set_title('Training performance')\n",
        "\n",
        "fpr, tpr, _ = roc_curve(y_valid[:, 1], y_prob_val[:, 1])\n",
        "ax1.plot(fpr, tpr, label='ROC curve (area = {:.2f})'.format(valid_auc[epoch]))\n",
        "ax1.plot([0, 1], [0, 1], linestyle='--')\n",
        "ax1.set_xlim([0.0, 1.0])\n",
        "ax1.set_ylim([0.0, 1.05])\n",
        "ax1.set_xlabel('False Positive Rate')\n",
        "ax1.set_ylabel('True Positive Rate')\n",
        "ax1.set_title('ROC Curve')\n",
        "\n",
        "for a in [ax, ax1]:\n",
        "    a.spines['top'].set_visible(False)\n",
        "    a.spines['right'].set_visible(False)\n",
        "    a.legend(frameon=False)\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 59,
      "outputs": []
    },
    {
      "metadata": {
        "id": "FjwYfNTFLyQl",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 369
        },
        "outputId": "f0cea9cc-9206-48ac-cf04-6295f2072e4d"
      },
      "cell_type": "code",
      "source": [
        "fig, (ax, ax1) = plt.subplots(1, 2, figsize=[14, 5])\n",
        "\n",
        "# Precision recall curve\n",
        "precision, recall, _ = precision_recall_curve(y_valid[:, 1], y_prob_val[:, 1])\n",
        "ax.step(recall, precision, color='b', alpha=0.2, where='post')\n",
        "ax.fill_between(recall, precision, step='post', alpha=0.2, color='b')\n",
        "ax.set_xlabel('Recall')\n",
        "ax.set_ylabel('Precision')\n",
        "ax.set_ylim([0.0, 1.05])\n",
        "ax.set_xlim([0.0, 1.0])\n",
        "ax.spines['right'].set_visible(False)\n",
        "ax.spines['top'].set_visible(False)\n",
        "ax.set_title('Precision - recall curve')\n",
        "\n",
        "# Confusion matrix\n",
        "cnf_matrix = confusion_matrix(y_valid[:, 1], np.argmax(y_prob_val, axis=1))\n",
        "cmap = sns.diverging_palette(220, 10, as_cmap=True)\n",
        "heatmap = sns.heatmap(cnf_matrix, annot=True, fmt='d', ax=ax1, cmap=cmap, center=0)\n",
        "ax1.set_title('Confusion matrix heatmap')\n",
        "ax1.set_ylabel('True label')\n",
        "ax1.set_xlabel('Predicted label')\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 60,
      "outputs": []
    },
    {
      "metadata": {
        "id": "HQadVP7CLzK9",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "out_df = pd.DataFrame({'SK_ID_CURR': meta_df['SK_ID_CURR'][len_train:], 'TARGET': y_prob[:, 1]})\n",
        "out_df.to_csv(path + 'nn_submission.csv', index=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "XHFKLjFFv7zR",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}
{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\lib\\site-packages\\h5py\\__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import gc\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_colwidth', -1)\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn.preprocessing import LabelEncoder, MinMaxScaler, StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_auc_score, roc_curve, precision_recall_curve, confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from timeit import default_timer\n",
    "start = default_timer()\n",
    "\n",
    "def start_timer():\n",
    "    st = default_timer()\n",
    "    return st\n",
    "def stop_timer(st):\n",
    "    runtime = default_timer() - st\n",
    "    print (\"Elapsed time(sec): \", round(runtime,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data sets...\n",
      "Data loaded.\n",
      "Main application training data set shape = (307511, 122)\n",
      "Main application test data set shape = (48744, 121)\n",
      "Positive target proportion = 0.08\n",
      "Elapsed time(sec):  68.02\n"
     ]
    }
   ],
   "source": [
    "st = start_timer()\n",
    "path = \"./data/\"\n",
    "print('Loading data sets...')\n",
    "\n",
    "sample_size = None\n",
    "app_train_df = pd.read_csv(path + 'application_train.csv')\n",
    "app_test_df = pd.read_csv(path + 'application_test.csv')\n",
    "bureau_df = pd.read_csv(path + 'bureau.csv')\n",
    "bureau_balance_df = pd.read_csv(path + 'bureau_balance.csv')\n",
    "credit_card_df = pd.read_csv(path + 'credit_card_balance.csv')\n",
    "pos_cash_df = pd.read_csv(path + 'POS_CASH_balance.csv')\n",
    "prev_app_df = pd.read_csv(path + 'previous_application.csv')\n",
    "install_df = pd.read_csv(path + 'installments_payments.csv')\n",
    "\n",
    "print('Data loaded.\\nMain application training data set shape = {}'.format(app_train_df.shape))\n",
    "print('Main application test data set shape = {}'.format(app_test_df.shape))\n",
    "print('Positive target proportion = {:.2f}'.format(app_train_df['TARGET'].mean()))\n",
    "stop_timer(st)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SK_ID_CURR</th>\n",
       "      <th>TARGET</th>\n",
       "      <th>NAME_CONTRACT_TYPE</th>\n",
       "      <th>CODE_GENDER</th>\n",
       "      <th>FLAG_OWN_CAR</th>\n",
       "      <th>FLAG_OWN_REALTY</th>\n",
       "      <th>CNT_CHILDREN</th>\n",
       "      <th>AMT_INCOME_TOTAL</th>\n",
       "      <th>AMT_CREDIT</th>\n",
       "      <th>AMT_ANNUITY</th>\n",
       "      <th>...</th>\n",
       "      <th>FLAG_DOCUMENT_18</th>\n",
       "      <th>FLAG_DOCUMENT_19</th>\n",
       "      <th>FLAG_DOCUMENT_20</th>\n",
       "      <th>FLAG_DOCUMENT_21</th>\n",
       "      <th>AMT_REQ_CREDIT_BUREAU_HOUR</th>\n",
       "      <th>AMT_REQ_CREDIT_BUREAU_DAY</th>\n",
       "      <th>AMT_REQ_CREDIT_BUREAU_WEEK</th>\n",
       "      <th>AMT_REQ_CREDIT_BUREAU_MON</th>\n",
       "      <th>AMT_REQ_CREDIT_BUREAU_QRT</th>\n",
       "      <th>AMT_REQ_CREDIT_BUREAU_YEAR</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100002</td>\n",
       "      <td>1</td>\n",
       "      <td>Cash loans</td>\n",
       "      <td>M</td>\n",
       "      <td>N</td>\n",
       "      <td>Y</td>\n",
       "      <td>0</td>\n",
       "      <td>202500.0</td>\n",
       "      <td>406597.5</td>\n",
       "      <td>24700.5</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>100003</td>\n",
       "      <td>0</td>\n",
       "      <td>Cash loans</td>\n",
       "      <td>F</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>0</td>\n",
       "      <td>270000.0</td>\n",
       "      <td>1293502.5</td>\n",
       "      <td>35698.5</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>100004</td>\n",
       "      <td>0</td>\n",
       "      <td>Revolving loans</td>\n",
       "      <td>M</td>\n",
       "      <td>Y</td>\n",
       "      <td>Y</td>\n",
       "      <td>0</td>\n",
       "      <td>67500.0</td>\n",
       "      <td>135000.0</td>\n",
       "      <td>6750.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>100006</td>\n",
       "      <td>0</td>\n",
       "      <td>Cash loans</td>\n",
       "      <td>F</td>\n",
       "      <td>N</td>\n",
       "      <td>Y</td>\n",
       "      <td>0</td>\n",
       "      <td>135000.0</td>\n",
       "      <td>312682.5</td>\n",
       "      <td>29686.5</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>100007</td>\n",
       "      <td>0</td>\n",
       "      <td>Cash loans</td>\n",
       "      <td>M</td>\n",
       "      <td>N</td>\n",
       "      <td>Y</td>\n",
       "      <td>0</td>\n",
       "      <td>121500.0</td>\n",
       "      <td>513000.0</td>\n",
       "      <td>21865.5</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 122 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   SK_ID_CURR  TARGET NAME_CONTRACT_TYPE CODE_GENDER FLAG_OWN_CAR  \\\n",
       "0  100002      1       Cash loans         M           N             \n",
       "1  100003      0       Cash loans         F           N             \n",
       "2  100004      0       Revolving loans    M           Y             \n",
       "3  100006      0       Cash loans         F           N             \n",
       "4  100007      0       Cash loans         M           N             \n",
       "\n",
       "  FLAG_OWN_REALTY  CNT_CHILDREN  AMT_INCOME_TOTAL  AMT_CREDIT  AMT_ANNUITY  \\\n",
       "0  Y               0             202500.0          406597.5    24700.5       \n",
       "1  N               0             270000.0          1293502.5   35698.5       \n",
       "2  Y               0             67500.0           135000.0    6750.0        \n",
       "3  Y               0             135000.0          312682.5    29686.5       \n",
       "4  Y               0             121500.0          513000.0    21865.5       \n",
       "\n",
       "              ...              FLAG_DOCUMENT_18 FLAG_DOCUMENT_19  \\\n",
       "0             ...              0                 0                 \n",
       "1             ...              0                 0                 \n",
       "2             ...              0                 0                 \n",
       "3             ...              0                 0                 \n",
       "4             ...              0                 0                 \n",
       "\n",
       "  FLAG_DOCUMENT_20 FLAG_DOCUMENT_21 AMT_REQ_CREDIT_BUREAU_HOUR  \\\n",
       "0  0                0                0.0                         \n",
       "1  0                0                0.0                         \n",
       "2  0                0                0.0                         \n",
       "3  0                0               NaN                          \n",
       "4  0                0                0.0                         \n",
       "\n",
       "  AMT_REQ_CREDIT_BUREAU_DAY  AMT_REQ_CREDIT_BUREAU_WEEK  \\\n",
       "0  0.0                       0.0                          \n",
       "1  0.0                       0.0                          \n",
       "2  0.0                       0.0                          \n",
       "3 NaN                       NaN                           \n",
       "4  0.0                       0.0                          \n",
       "\n",
       "   AMT_REQ_CREDIT_BUREAU_MON  AMT_REQ_CREDIT_BUREAU_QRT  \\\n",
       "0  0.0                        0.0                         \n",
       "1  0.0                        0.0                         \n",
       "2  0.0                        0.0                         \n",
       "3 NaN                        NaN                          \n",
       "4  0.0                        0.0                         \n",
       "\n",
       "   AMT_REQ_CREDIT_BUREAU_YEAR  \n",
       "0  1.0                         \n",
       "1  0.0                         \n",
       "2  0.0                         \n",
       "3 NaN                          \n",
       "4  0.0                         \n",
       "\n",
       "[5 rows x 122 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "app_train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def feature_engineering(app_data, bureau_df, bureau_balance_df, credit_card_df,\n",
    "                        pos_cash_df, prev_app_df, install_df):\n",
    "    \"\"\" \n",
    "    Process the input dataframes into a single one containing all the features. Requires\n",
    "    a lot of aggregating of the supplementary datasets such that they have an entry per\n",
    "    customer.\n",
    "    \n",
    "    Also, add any new features created from the existing ones\n",
    "    \"\"\"\n",
    "    # Clean Data\n",
    "    # Days_Employed\n",
    "    app_data['DAYS_EMPLOYED'] = app_data['DAYS_EMPLOYED'].replace({365243: np.nan}, inplace = True)\n",
    "    \n",
    "    # # Add new features\n",
    "    \n",
    "    # Amount loaned relative to salary\n",
    "    app_data['LOAN_INCOME_RATIO'] = app_data['AMT_CREDIT'] / app_data['AMT_INCOME_TOTAL']\n",
    "    app_data['ANNUITY_INCOME_RATIO'] = app_data['AMT_ANNUITY'] / app_data['AMT_INCOME_TOTAL']\n",
    "    app_data['ANNUITY LENGTH'] = app_data['AMT_CREDIT'] / app_data['AMT_ANNUITY']\n",
    "    #app_data['DAY_EMPLOYED_PERCENT'] = app_data['DAYS_EMPLOYED'] / app_data['DAYS_BIRTH']\n",
    "    \n",
    "    # # Aggregate and merge supplementary datasets\n",
    "    print('Combined train & test input shape before any merging  = {}'.format(app_data.shape))\n",
    "\n",
    "    # Previous applications\n",
    "    agg_funs = {'SK_ID_CURR': 'count', 'AMT_CREDIT': 'sum'}\n",
    "    prev_apps = prev_app_df.groupby('SK_ID_CURR').agg(agg_funs)\n",
    "    prev_apps.columns = ['PREV APP COUNT', 'TOTAL PREV LOAN AMT']\n",
    "    merged_df = app_data.merge(prev_apps, left_on='SK_ID_CURR', right_index=True, how='left')\n",
    "\n",
    "    # Average the rest of the previous app data\n",
    "    prev_apps_avg = prev_app_df.groupby('SK_ID_CURR').mean()\n",
    "    merged_df = merged_df.merge(prev_apps_avg, left_on='SK_ID_CURR', right_index=True,\n",
    "                                how='left', suffixes=['', '_PAVG'])\n",
    "    print('Shape after merging with previous apps num data = {}'.format(merged_df.shape))\n",
    "\n",
    "    # Previous app categorical features\n",
    "    prev_app_df, cat_feats, _ = process_dataframe(prev_app_df)\n",
    "    prev_apps_cat_avg = prev_app_df[cat_feats + ['SK_ID_CURR']].groupby('SK_ID_CURR')\\\n",
    "                             .agg({k: lambda x: str(x.mode().iloc[0]) for k in cat_feats})\n",
    "    merged_df = merged_df.merge(prev_apps_cat_avg, left_on='SK_ID_CURR', right_index=True,\n",
    "                            how='left', suffixes=['', '_BAVG'])\n",
    "    print('Shape after merging with previous apps cat data = {}'.format(merged_df.shape))\n",
    "\n",
    "    # Credit card data - numerical features\n",
    "    wm = lambda x: np.average(x, weights=-1/credit_card_df.loc[x.index, 'MONTHS_BALANCE'])\n",
    "    credit_card_avgs = credit_card_df.groupby('SK_ID_CURR').agg(wm)   \n",
    "    merged_df = merged_df.merge(credit_card_avgs, left_on='SK_ID_CURR', right_index=True,\n",
    "                                how='left', suffixes=['', '_CCAVG'])\n",
    "\n",
    "    # Credit card data - categorical features\n",
    "    most_recent_index = credit_card_df.groupby('SK_ID_CURR')['MONTHS_BALANCE'].idxmax()\n",
    "    cat_feats = credit_card_df.columns[credit_card_df.dtypes == 'object'].tolist()  + ['SK_ID_CURR']\n",
    "    merged_df = merged_df.merge(credit_card_df.loc[most_recent_index, cat_feats], left_on='SK_ID_CURR', right_on='SK_ID_CURR',\n",
    "                       how='left', suffixes=['', '_CCAVG'])\n",
    "    print('Shape after merging with credit card data = {}'.format(merged_df.shape))\n",
    "\n",
    "    # Credit bureau data - numerical features\n",
    "    credit_bureau_avgs = bureau_df.groupby('SK_ID_CURR').mean()\n",
    "    merged_df = merged_df.merge(credit_bureau_avgs, left_on='SK_ID_CURR', right_index=True,\n",
    "                                how='left', suffixes=['', '_BAVG'])\n",
    "    print('Shape after merging with credit bureau data = {}'.format(merged_df.shape))\n",
    "\n",
    "    # Bureau balance data\n",
    "    most_recent_index = bureau_balance_df.groupby('SK_ID_BUREAU')['MONTHS_BALANCE'].idxmax()\n",
    "    bureau_balance_df = bureau_balance_df.loc[most_recent_index, :]\n",
    "    merged_df = merged_df.merge(bureau_balance_df, left_on='SK_ID_BUREAU', right_on='SK_ID_BUREAU',\n",
    "                            how='left', suffixes=['', '_B_B'])\n",
    "    print('Shape after merging with bureau balance data = {}'.format(merged_df.shape))\n",
    "\n",
    "    # Pos cash data - weight values by recency when averaging\n",
    "    wm = lambda x: np.average(x, weights=-1/pos_cash_df.loc[x.index, 'MONTHS_BALANCE'])\n",
    "    f = {'CNT_INSTALMENT': wm, 'CNT_INSTALMENT_FUTURE': wm, 'SK_DPD': wm, 'SK_DPD_DEF':wm}\n",
    "    cash_avg = pos_cash_df.groupby('SK_ID_CURR')['CNT_INSTALMENT','CNT_INSTALMENT_FUTURE',\n",
    "                                                 'SK_DPD', 'SK_DPD_DEF'].agg(f)\n",
    "    merged_df = merged_df.merge(cash_avg, left_on='SK_ID_CURR', right_index=True,\n",
    "                                how='left', suffixes=['', '_CAVG'])\n",
    "\n",
    "    # Pos cash data data - categorical features\n",
    "    most_recent_index = pos_cash_df.groupby('SK_ID_CURR')['MONTHS_BALANCE'].idxmax()\n",
    "    cat_feats = pos_cash_df.columns[pos_cash_df.dtypes == 'object'].tolist()  + ['SK_ID_CURR']\n",
    "    merged_df = merged_df.merge(pos_cash_df.loc[most_recent_index, cat_feats], left_on='SK_ID_CURR', right_on='SK_ID_CURR',\n",
    "                       how='left', suffixes=['', '_CAVG'])\n",
    "    print('Shape after merging with pos cash data = {}'.format(merged_df.shape))\n",
    "\n",
    "    # Installments data\n",
    "    ins_avg = install_df.groupby('SK_ID_CURR').mean()\n",
    "    merged_df = merged_df.merge(ins_avg, left_on='SK_ID_CURR', right_index=True,\n",
    "                                how='left', suffixes=['', '_IAVG'])\n",
    "    print('Shape after merging with installments data = {}'.format(merged_df.shape))\n",
    "\n",
    "    # Add more value counts\n",
    "    merged_df = merged_df.merge(pd.DataFrame(bureau_df['SK_ID_CURR'].value_counts()), left_on='SK_ID_CURR', \n",
    "                                right_index=True, how='left', suffixes=['', '_CNT_BUREAU'])\n",
    "    merged_df = merged_df.merge(pd.DataFrame(credit_card_df['SK_ID_CURR'].value_counts()), left_on='SK_ID_CURR', \n",
    "                                right_index=True, how='left', suffixes=['', '_CNT_CRED_CARD'])\n",
    "    merged_df = merged_df.merge(pd.DataFrame(pos_cash_df['SK_ID_CURR'].value_counts()), left_on='SK_ID_CURR', \n",
    "                                right_index=True, how='left', suffixes=['', '_CNT_POS_CASH'])\n",
    "    merged_df = merged_df.merge(pd.DataFrame(install_df['SK_ID_CURR'].value_counts()), left_on='SK_ID_CURR', \n",
    "                                right_index=True, how='left', suffixes=['', '_CNT_INSTALL'])\n",
    "    print('Shape after merging with counts data = {}'.format(merged_df.shape))\n",
    "\n",
    "    return merged_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def process_dataframe(input_df, encoder_dict=None):\n",
    "    \"\"\" Process a dataframe into a form useable by LightGBM \"\"\"\n",
    "\n",
    "    # Label encode categoricals\n",
    "    categorical_feats = input_df.columns[input_df.dtypes == 'object']\n",
    "    categorical_feats = categorical_feats\n",
    "    encoder_dict = {}\n",
    "    for feat in categorical_feats:\n",
    "        encoder = LabelEncoder()\n",
    "        input_df[feat] = encoder.fit_transform(input_df[feat].fillna('NULL'))\n",
    "        encoder_dict[feat] = encoder\n",
    "\n",
    "    return input_df, categorical_feats.tolist(), encoder_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combined train & test input shape before any merging  = (356255, 125)\n",
      "Shape after merging with previous apps num data = (356255, 147)\n",
      "Shape after merging with previous apps cat data = (356255, 163)\n",
      "Shape after merging with credit card data = (356255, 185)\n",
      "Shape after merging with credit bureau data = (356255, 198)\n",
      "Shape after merging with bureau balance data = (356255, 200)\n",
      "Shape after merging with pos cash data = (356255, 205)\n",
      "Shape after merging with installments data = (356255, 212)\n",
      "Shape after merging with counts data = (356255, 216)\n",
      "Elapsed time(sec):  2353.6\n"
     ]
    }
   ],
   "source": [
    "st = start_timer()\n",
    "# Merge the datasets into a single one for training\n",
    "len_train = len(app_train_df)\n",
    "app_both = pd.concat([app_train_df, app_test_df])\n",
    "merged_df = feature_engineering(app_both, bureau_df, bureau_balance_df, credit_card_df,\n",
    "                                pos_cash_df, prev_app_df, install_df)\n",
    "\n",
    "# Separate metadata\n",
    "meta_cols = ['SK_ID_CURR', 'SK_ID_BUREAU', 'SK_ID_PREV']\n",
    "# meta_cols = ['SK_ID_CURR']\n",
    "meta_df = merged_df[meta_cols]\n",
    "merged_df.drop(meta_cols, axis=1, inplace=True)\n",
    "\n",
    "# # Process the data set.\n",
    "merged_df, categorical_feats, encoder_dict = process_dataframe(input_df=merged_df)\n",
    "stop_timer(st)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'CHANNEL_TYPE': LabelEncoder(),\n",
       " 'CODE_GENDER': LabelEncoder(),\n",
       " 'CODE_REJECT_REASON': LabelEncoder(),\n",
       " 'DAYS_EMPLOYED': LabelEncoder(),\n",
       " 'EMERGENCYSTATE_MODE': LabelEncoder(),\n",
       " 'FLAG_LAST_APPL_PER_CONTRACT': LabelEncoder(),\n",
       " 'FLAG_OWN_CAR': LabelEncoder(),\n",
       " 'FLAG_OWN_REALTY': LabelEncoder(),\n",
       " 'FONDKAPREMONT_MODE': LabelEncoder(),\n",
       " 'HOUSETYPE_MODE': LabelEncoder(),\n",
       " 'NAME_CASH_LOAN_PURPOSE': LabelEncoder(),\n",
       " 'NAME_CLIENT_TYPE': LabelEncoder(),\n",
       " 'NAME_CONTRACT_STATUS': LabelEncoder(),\n",
       " 'NAME_CONTRACT_STATUS_CAVG': LabelEncoder(),\n",
       " 'NAME_CONTRACT_STATUS_CCAVG': LabelEncoder(),\n",
       " 'NAME_CONTRACT_TYPE': LabelEncoder(),\n",
       " 'NAME_CONTRACT_TYPE_BAVG': LabelEncoder(),\n",
       " 'NAME_EDUCATION_TYPE': LabelEncoder(),\n",
       " 'NAME_FAMILY_STATUS': LabelEncoder(),\n",
       " 'NAME_GOODS_CATEGORY': LabelEncoder(),\n",
       " 'NAME_HOUSING_TYPE': LabelEncoder(),\n",
       " 'NAME_INCOME_TYPE': LabelEncoder(),\n",
       " 'NAME_PAYMENT_TYPE': LabelEncoder(),\n",
       " 'NAME_PORTFOLIO': LabelEncoder(),\n",
       " 'NAME_PRODUCT_TYPE': LabelEncoder(),\n",
       " 'NAME_SELLER_INDUSTRY': LabelEncoder(),\n",
       " 'NAME_TYPE_SUITE': LabelEncoder(),\n",
       " 'NAME_TYPE_SUITE_BAVG': LabelEncoder(),\n",
       " 'NAME_YIELD_GROUP': LabelEncoder(),\n",
       " 'OCCUPATION_TYPE': LabelEncoder(),\n",
       " 'ORGANIZATION_TYPE': LabelEncoder(),\n",
       " 'PRODUCT_COMBINATION': LabelEncoder(),\n",
       " 'STATUS': LabelEncoder(),\n",
       " 'WALLSMATERIAL_MODE': LabelEncoder(),\n",
       " 'WEEKDAY_APPR_PROCESS_START': LabelEncoder(),\n",
       " 'WEEKDAY_APPR_PROCESS_START_BAVG': LabelEncoder()}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['CODE_GENDER',\n",
       " 'DAYS_EMPLOYED',\n",
       " 'EMERGENCYSTATE_MODE',\n",
       " 'FLAG_OWN_CAR',\n",
       " 'FLAG_OWN_REALTY',\n",
       " 'FONDKAPREMONT_MODE',\n",
       " 'HOUSETYPE_MODE',\n",
       " 'NAME_CONTRACT_TYPE',\n",
       " 'NAME_EDUCATION_TYPE',\n",
       " 'NAME_FAMILY_STATUS',\n",
       " 'NAME_HOUSING_TYPE',\n",
       " 'NAME_INCOME_TYPE',\n",
       " 'NAME_TYPE_SUITE',\n",
       " 'OCCUPATION_TYPE',\n",
       " 'ORGANIZATION_TYPE',\n",
       " 'WALLSMATERIAL_MODE',\n",
       " 'WEEKDAY_APPR_PROCESS_START',\n",
       " 'NAME_CONTRACT_TYPE_BAVG',\n",
       " 'WEEKDAY_APPR_PROCESS_START_BAVG',\n",
       " 'FLAG_LAST_APPL_PER_CONTRACT',\n",
       " 'NAME_CASH_LOAN_PURPOSE',\n",
       " 'NAME_CONTRACT_STATUS',\n",
       " 'NAME_PAYMENT_TYPE',\n",
       " 'CODE_REJECT_REASON',\n",
       " 'NAME_TYPE_SUITE_BAVG',\n",
       " 'NAME_CLIENT_TYPE',\n",
       " 'NAME_GOODS_CATEGORY',\n",
       " 'NAME_PORTFOLIO',\n",
       " 'NAME_PRODUCT_TYPE',\n",
       " 'CHANNEL_TYPE',\n",
       " 'NAME_SELLER_INDUSTRY',\n",
       " 'NAME_YIELD_GROUP',\n",
       " 'PRODUCT_COMBINATION',\n",
       " 'NAME_CONTRACT_STATUS_CCAVG',\n",
       " 'STATUS',\n",
       " 'NAME_CONTRACT_STATUS_CAVG']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "categorical_feats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AMT_ANNUITY</th>\n",
       "      <th>AMT_CREDIT</th>\n",
       "      <th>AMT_GOODS_PRICE</th>\n",
       "      <th>AMT_INCOME_TOTAL</th>\n",
       "      <th>AMT_REQ_CREDIT_BUREAU_DAY</th>\n",
       "      <th>AMT_REQ_CREDIT_BUREAU_HOUR</th>\n",
       "      <th>AMT_REQ_CREDIT_BUREAU_MON</th>\n",
       "      <th>AMT_REQ_CREDIT_BUREAU_QRT</th>\n",
       "      <th>AMT_REQ_CREDIT_BUREAU_WEEK</th>\n",
       "      <th>AMT_REQ_CREDIT_BUREAU_YEAR</th>\n",
       "      <th>...</th>\n",
       "      <th>NUM_INSTALMENT_VERSION</th>\n",
       "      <th>NUM_INSTALMENT_NUMBER</th>\n",
       "      <th>DAYS_INSTALMENT</th>\n",
       "      <th>DAYS_ENTRY_PAYMENT</th>\n",
       "      <th>AMT_INSTALMENT</th>\n",
       "      <th>AMT_PAYMENT</th>\n",
       "      <th>SK_ID_CURR_CNT_BUREAU</th>\n",
       "      <th>SK_ID_CURR_CNT_CRED_CARD</th>\n",
       "      <th>SK_ID_CURR_CNT_POS_CASH</th>\n",
       "      <th>SK_ID_CURR_CNT_INSTALL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>24700.5</td>\n",
       "      <td>406597.5</td>\n",
       "      <td>351000.0</td>\n",
       "      <td>202500.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.052632</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>-295.000000</td>\n",
       "      <td>-315.421053</td>\n",
       "      <td>11559.247105</td>\n",
       "      <td>11559.247105</td>\n",
       "      <td>8.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>19.0</td>\n",
       "      <td>19.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>35698.5</td>\n",
       "      <td>1293502.5</td>\n",
       "      <td>1129500.0</td>\n",
       "      <td>270000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.040000</td>\n",
       "      <td>5.080000</td>\n",
       "      <td>-1378.160000</td>\n",
       "      <td>-1385.320000</td>\n",
       "      <td>64754.586000</td>\n",
       "      <td>64754.586000</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>28.0</td>\n",
       "      <td>25.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6750.0</td>\n",
       "      <td>135000.0</td>\n",
       "      <td>135000.0</td>\n",
       "      <td>67500.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.333333</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>-754.000000</td>\n",
       "      <td>-761.666667</td>\n",
       "      <td>7096.155000</td>\n",
       "      <td>7096.155000</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>29686.5</td>\n",
       "      <td>312682.5</td>\n",
       "      <td>297000.0</td>\n",
       "      <td>135000.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>1.125000</td>\n",
       "      <td>4.437500</td>\n",
       "      <td>-252.250000</td>\n",
       "      <td>-271.625000</td>\n",
       "      <td>62947.088438</td>\n",
       "      <td>62947.088438</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>16.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>21865.5</td>\n",
       "      <td>513000.0</td>\n",
       "      <td>513000.0</td>\n",
       "      <td>121500.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.166667</td>\n",
       "      <td>7.045455</td>\n",
       "      <td>-1028.606061</td>\n",
       "      <td>-1032.242424</td>\n",
       "      <td>12666.444545</td>\n",
       "      <td>12214.060227</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>66.0</td>\n",
       "      <td>66.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 213 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   AMT_ANNUITY  AMT_CREDIT  AMT_GOODS_PRICE  AMT_INCOME_TOTAL  \\\n",
       "0  24700.5      406597.5    351000.0         202500.0           \n",
       "1  35698.5      1293502.5   1129500.0        270000.0           \n",
       "2  6750.0       135000.0    135000.0         67500.0            \n",
       "3  29686.5      312682.5    297000.0         135000.0           \n",
       "4  21865.5      513000.0    513000.0         121500.0           \n",
       "\n",
       "   AMT_REQ_CREDIT_BUREAU_DAY  AMT_REQ_CREDIT_BUREAU_HOUR  \\\n",
       "0  0.0                        0.0                          \n",
       "1  0.0                        0.0                          \n",
       "2  0.0                        0.0                          \n",
       "3 NaN                        NaN                           \n",
       "4  0.0                        0.0                          \n",
       "\n",
       "   AMT_REQ_CREDIT_BUREAU_MON  AMT_REQ_CREDIT_BUREAU_QRT  \\\n",
       "0  0.0                        0.0                         \n",
       "1  0.0                        0.0                         \n",
       "2  0.0                        0.0                         \n",
       "3 NaN                        NaN                          \n",
       "4  0.0                        0.0                         \n",
       "\n",
       "   AMT_REQ_CREDIT_BUREAU_WEEK  AMT_REQ_CREDIT_BUREAU_YEAR  \\\n",
       "0  0.0                         1.0                          \n",
       "1  0.0                         0.0                          \n",
       "2  0.0                         0.0                          \n",
       "3 NaN                         NaN                           \n",
       "4  0.0                         0.0                          \n",
       "\n",
       "            ...            NUM_INSTALMENT_VERSION  NUM_INSTALMENT_NUMBER  \\\n",
       "0           ...            1.052632                10.000000               \n",
       "1           ...            1.040000                5.080000                \n",
       "2           ...            1.333333                2.000000                \n",
       "3           ...            1.125000                4.437500                \n",
       "4           ...            1.166667                7.045455                \n",
       "\n",
       "   DAYS_INSTALMENT  DAYS_ENTRY_PAYMENT  AMT_INSTALMENT   AMT_PAYMENT  \\\n",
       "0 -295.000000      -315.421053          11559.247105    11559.247105   \n",
       "1 -1378.160000     -1385.320000         64754.586000    64754.586000   \n",
       "2 -754.000000      -761.666667          7096.155000     7096.155000    \n",
       "3 -252.250000      -271.625000          62947.088438    62947.088438   \n",
       "4 -1028.606061     -1032.242424         12666.444545    12214.060227   \n",
       "\n",
       "   SK_ID_CURR_CNT_BUREAU  SK_ID_CURR_CNT_CRED_CARD  SK_ID_CURR_CNT_POS_CASH  \\\n",
       "0  8.0                   NaN                        19.0                      \n",
       "1  4.0                   NaN                        28.0                      \n",
       "2  2.0                   NaN                        4.0                       \n",
       "3 NaN                     6.0                       21.0                      \n",
       "4  1.0                   NaN                        66.0                      \n",
       "\n",
       "   SK_ID_CURR_CNT_INSTALL  \n",
       "0  19.0                    \n",
       "1  25.0                    \n",
       "2  3.0                     \n",
       "3  16.0                    \n",
       "4  66.0                    \n",
       "\n",
       "[5 rows x 213 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed time(sec):  0.0\n"
     ]
    }
   ],
   "source": [
    "st = start_timer()\n",
    "# Capture other categorical features not as object data types:\n",
    "non_obj_categoricals = [\n",
    "    'FONDKAPREMONT_MODE',\n",
    "    'HOUR_APPR_PROCESS_START',\n",
    "    'HOUSETYPE_MODE',\n",
    "    'NAME_EDUCATION_TYPE',\n",
    "    'NAME_FAMILY_STATUS', \n",
    "    'NAME_HOUSING_TYPE',\n",
    "    'NAME_INCOME_TYPE', \n",
    "    'NAME_TYPE_SUITE', \n",
    "    'OCCUPATION_TYPE',\n",
    "    'ORGANIZATION_TYPE', \n",
    "    'WALLSMATERIAL_MODE',\n",
    "    'WEEKDAY_APPR_PROCESS_START', \n",
    "    'NAME_CONTRACT_TYPE_BAVG',\n",
    "    'WEEKDAY_APPR_PROCESS_START_BAVG',\n",
    "    'NAME_CASH_LOAN_PURPOSE', \n",
    "    'NAME_CONTRACT_STATUS', \n",
    "    'NAME_PAYMENT_TYPE',\n",
    "    'CODE_REJECT_REASON', \n",
    "    'NAME_TYPE_SUITE_BAVG', \n",
    "    'NAME_CLIENT_TYPE',\n",
    "    'NAME_GOODS_CATEGORY', \n",
    "    'NAME_PORTFOLIO', \n",
    "    'NAME_PRODUCT_TYPE',\n",
    "    'CHANNEL_TYPE', \n",
    "    'NAME_SELLER_INDUSTRY', \n",
    "    'NAME_YIELD_GROUP',\n",
    "    'PRODUCT_COMBINATION', \n",
    "    'NAME_CONTRACT_STATUS_CCAVG', \n",
    "    'STATUS',\n",
    "    'NAME_CONTRACT_STATUS_CAVG'\n",
    "]\n",
    "categorical_feats = categorical_feats + non_obj_categoricals\n",
    "stop_timer(st)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed time(sec):  0.19\n"
     ]
    }
   ],
   "source": [
    "st = start_timer()\n",
    "# Extract target before scaling\n",
    "labels = merged_df.pop('TARGET')\n",
    "labels = labels[:len_train]\n",
    "\n",
    "# Reshape (one-hot)\n",
    "target = np.zeros([len(labels), len(np.unique(labels))])\n",
    "target[:, 0] = labels == 0\n",
    "target[:, 1] = labels == 1\n",
    "stop_timer(st)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns dropped for being over 80.0% null:\n",
      "RATE_INTEREST_PRIMARY\n",
      "RATE_INTEREST_PRIVILEGED\n",
      "AMT_DRAWINGS_ATM_CURRENT\n",
      "AMT_DRAWINGS_OTHER_CURRENT\n",
      "AMT_DRAWINGS_POS_CURRENT\n",
      "AMT_INST_MIN_REGULARITY\n",
      "AMT_PAYMENT_CURRENT\n",
      "CNT_DRAWINGS_ATM_CURRENT\n",
      "CNT_DRAWINGS_OTHER_CURRENT\n",
      "CNT_DRAWINGS_POS_CURRENT\n",
      "CNT_INSTALMENT_MATURE_CUM\n",
      "MONTHS_BALANCE_B_B\n",
      "Elapsed time(sec):  4.56\n"
     ]
    }
   ],
   "source": [
    "st = start_timer()\n",
    "null_counts = merged_df.isnull().sum()\n",
    "null_counts = null_counts[null_counts > 0]\n",
    "null_ratios = null_counts / len(merged_df)\n",
    "\n",
    "# Drop columns over x% null\n",
    "null_thresh = .8\n",
    "null_cols = null_ratios[null_ratios > null_thresh].index\n",
    "merged_df.drop(null_cols, axis=1, inplace=True)\n",
    "print('Columns dropped for being over {}% null:'.format(100*null_thresh))\n",
    "for col in null_cols:\n",
    "    print(col)\n",
    "    if col in categorical_feats:\n",
    "        categorical_feats.pop(col)\n",
    "    \n",
    "# Fill the rest with the mean (TODO: do something better!)\n",
    "merged_df.fillna(merged_df.median(), inplace=True)\n",
    "# merged_df.fillna(0, inplace=True)\n",
    "stop_timer(st)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(356255, 200)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>column_index</th>\n",
       "      <th>feature</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>18</td>\n",
       "      <td>CODE_GENDER</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>23</td>\n",
       "      <td>DAYS_EMPLOYED</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>32</td>\n",
       "      <td>EMERGENCYSTATE_MODE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>63</td>\n",
       "      <td>FLAG_OWN_CAR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>64</td>\n",
       "      <td>FLAG_OWN_REALTY</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   column_index              feature\n",
       "0  18            CODE_GENDER        \n",
       "1  23            DAYS_EMPLOYED      \n",
       "2  32            EMERGENCYSTATE_MODE\n",
       "3  63            FLAG_OWN_CAR       \n",
       "4  64            FLAG_OWN_REALTY    "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cat_feats_idx = np.array([merged_df.columns.get_loc(x) for x in categorical_feats])\n",
    "int_feats_idx = [merged_df.columns.get_loc(x) for x in non_obj_categoricals]\n",
    "cat_feat_lookup = pd.DataFrame({'feature': categorical_feats, 'column_index': cat_feats_idx})\n",
    "cat_feat_lookup.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>column_index</th>\n",
       "      <th>feature</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>AMT_ANNUITY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>AMT_CREDIT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>AMT_GOODS_PRICE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>AMT_INCOME_TOTAL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>AMT_REQ_CREDIT_BUREAU_DAY</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   column_index                    feature\n",
       "0  0             AMT_ANNUITY              \n",
       "1  1             AMT_CREDIT               \n",
       "2  2             AMT_GOODS_PRICE          \n",
       "3  3             AMT_INCOME_TOTAL         \n",
       "4  4             AMT_REQ_CREDIT_BUREAU_DAY"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cont_feats_idx = np.array(\n",
    "    [merged_df.columns.get_loc(x) \n",
    "     for x in merged_df.columns[~merged_df.columns.isin(categorical_feats)]]\n",
    ")\n",
    "cont_feat_lookup = pd.DataFrame(\n",
    "    {'feature': merged_df.columns[~merged_df.columns.isin(categorical_feats)], \n",
    "     'column_index': cont_feats_idx}\n",
    ")\n",
    "cont_feat_lookup.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "final_col_names = merged_df.columns\n",
    "merged_df = merged_df.values\n",
    "merged_df[:, cont_feats_idx] = scaler.fit_transform(merged_df[:, cont_feats_idx])\n",
    "\n",
    "scaler_2 = MinMaxScaler(feature_range=(0, 1))\n",
    "merged_df[:, int_feats_idx] = scaler_2.fit_transform(merged_df[:, int_feats_idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Re-separate into labelled and unlabelled\n",
    "train_df = merged_df[:len_train]\n",
    "predict_df = merged_df[len_train:]\n",
    "# del merged_df, app_train_df, app_test_df, bureau_df, bureau_balance_df, credit_card_df, pos_cash_df, prev_app_df\n",
    "gc.collect()\n",
    "\n",
    "# Create a validation set to check training performance\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(train_df, target, test_size=0.1, random_state=2, stratify=target[:, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 0., 0., ..., 0., 1., 0.])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 1., 1., ..., 1., 0., 1.])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from collections import OrderedDict\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier\n",
    "\n",
    "rf_model = RandomForestClassifier( n_estimators=270,\n",
    "    max_depth=10,\n",
    "    min_impurity_split=None,\n",
    "    n_jobs=-1,\n",
    "    random_state=0,\n",
    "    class_weight='balanced') \n",
    "rf_model.fit(train_df, target[:,1])\n",
    "\n",
    "random_forest_pred = rf_model.predict_proba(predict_df)[:, 1]\n",
    "\n",
    "out_df = pd.DataFrame({'SK_ID_CURR': meta_df['SK_ID_CURR'][len_train:], 'TARGET': random_forest_pred})\n",
    "out_df.to_csv('forest_submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "random_forest_pred = rf_model.predict_proba(predict_df)[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.40991622, 0.59314894, 0.29199741, ..., 0.32978206, 0.35761369,\n",
       "       0.70414556])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_forest_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "out_df = pd.DataFrame({'SK_ID_CURR': meta_df['SK_ID_CURR'][len_train:], 'TARGET': random_forest_pred})\n",
    "out_df.to_csv('forest_submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot_feature_importances(df):\n",
    "    \"\"\"\n",
    "    Plot importances returned by a model. This can work with any measure of\n",
    "    feature importance provided that higher importance is better. \n",
    "    \n",
    "    Args:\n",
    "        df (dataframe): feature importances. Must have the features in a column\n",
    "        called `features` and the importances in a column called `importance\n",
    "        \n",
    "    Returns:\n",
    "        shows a plot of the 15 most importance features\n",
    "        \n",
    "        df (dataframe): feature importances sorted by importance (highest to lowest) \n",
    "        with a column for normalized importance\n",
    "        \"\"\"\n",
    "    \n",
    "    # Sort features according to importance\n",
    "    df = df.sort_values('importance', ascending = False).reset_index()\n",
    "    \n",
    "    # Normalize the feature importances to add up to one\n",
    "    df['importance_normalized'] = df['importance'] / df['importance'].sum()\n",
    "\n",
    "    # Make a horizontal bar chart of feature importances\n",
    "    plt.figure(figsize = (10, 6))\n",
    "    ax = plt.subplot()\n",
    "    \n",
    "    # Need to reverse the index to plot most important on top\n",
    "    ax.barh(list(reversed(list(df.index[:15]))), \n",
    "            df['importance_normalized'].head(15), \n",
    "            align = 'center', edgecolor = 'k')\n",
    "    \n",
    "    # Set the yticks and labels\n",
    "    ax.set_yticks(list(reversed(list(df.index[:15]))))\n",
    "    ax.set_yticklabels(df['feature'].head(15))\n",
    "    \n",
    "    # Plot labeling\n",
    "    plt.xlabel('Normalized Importance'); plt.title('Feature Importances')\n",
    "    plt.show()\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
